#### general settings
name: DANet
use_tb_logger: true
num_spks: 2
#### datasets
datasets:
  train:
    dataroot_mix: /home/likai/data1/create_scp/tr_mix.scp
    dataroot_targets: [/home/likai/data1/create_scp/tr_s1.scp,/home/likai/data1/create_scp/tr_s2.scp]

  val:
    dataroot_mix: /home/likai/data1/create_scp/cv_mix.scp
    dataroot_targets: [/home/likai/data1/create_scp/cv_s1.scp,/home/likai/data1/create_scp/cv_s2.scp]
  
  dataloader_setting:
    shuffle: true
    num_workers: 10  # per GPU
    batch_size: 1
    cmvn_file: /home/likai/data1/DANet/cmvn.ark
  
  audio_setting:
    window: hann
    nfft: 256
    window_length: 256
    hop_length: 64
    center: False
    is_mag: True  # abs(tf-domain)
    is_log: True   # log(tf-domain)
    chunk_size: 32000
    least: 16000
    

#### network structures
DANet:
  name: LSTM # RNN, LSTM, GRU
  num_layer: 4
  input_size: 129  # nfft/2+1
  hidden_cells: 300
  emb_D: 20
  dropout: 0.5
  batch_first: true
  bidirectional: true
  activation: Tanh

#### training settings: learning rate scheme, loss
train:
  epoch: 100
  early_stop: 10
  path: /home/likai/data1/DANet/checkpoint
  gpuid: [0,1,2,3,4,5,6,7]

#### Optimizer settings
optim:
  name: Adam   ### Adam, RMSprop, SGD
  lr: 1.0e-3
  momentum: 0.9
  weight_decay: 0
  clip_norm: 200
#### Resume training settings
resume:
  state: false
  path: /home/likai/data1/DANet/checkpoint


#### logger
logger:
  name: DANet
  path: /home/likai/data1/DANet/checkpoint
  screen: true
  tofile: false
  print_freq: 1000